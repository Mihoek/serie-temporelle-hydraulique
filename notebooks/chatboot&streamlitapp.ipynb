{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEZeEL9ufsOp"
      },
      "source": [
        "## Chatbot NLP pour le Syst√®me Hydraulique\n",
        "\n",
        "Cette section impl√©mente un assistant conversationnel pour interagir avec les mod√®les pr√©dictifs et l'utilisateur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AciXIh-Ge09y",
        "outputId": "e36377c3-8141-4230-a239-18e1b815a5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install pandas numpy scikit-learn joblib streamlit pyngrok nltk plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MErYdLpFO2l7",
        "outputId": "3a128c81-bb00-421d-e63f-632eb28e2668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from joblib import load, dump\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import streamlit as st\n",
        "import plotly.graph_objects as go\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "# Add this line to download the required resource for word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-ItVenYe2nV",
        "outputId": "96a1f88a-8115-4464-bff7-d7ec837c10a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and scalers loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Define paths\n",
        "base_path = '/content/drive/MyDrive/Projet_time_series/'\n",
        "data_path = base_path + 'Data_csv/'\n",
        "model_path = '/content/drive/MyDrive/Projet_time_series/Models/'\n",
        "scaler_X_path = model_path + 'scaler_X_inverse.joblib'\n",
        "scaler_y_path = model_path + 'scaler_y_inverse.joblib'\n",
        "model_inverse_mlp_path = model_path + 'model_inverse_mlp.joblib'\n",
        "\n",
        "# Load the inverse MLP model and scalers\n",
        "try:\n",
        "    model_inverse_mlp = load(model_inverse_mlp_path)\n",
        "    scaler_X_inverse = load(scaler_X_path)\n",
        "    scaler_y_inverse = load(scaler_y_path)\n",
        "    print(\"Model and scalers loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model or scalers: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me7PNxfQe98I",
        "outputId": "bdb9b4ce-321d-459f-9649-d87683813f64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (2205, 21)\n",
            "NaN values: 0\n"
          ]
        }
      ],
      "source": [
        "# Load sensor data and profile\n",
        "sensors = ['PS1', 'PS2', 'PS3', 'PS5', 'PS6', 'EPS1', 'FS1', 'FS2', 'TS1', 'TS2', 'TS3', 'TS4', 'VS1', 'CE', 'CP', 'SE']\n",
        "data_dict = {}\n",
        "\n",
        "for sensor in sensors:\n",
        "    df = pd.read_csv(f'{data_path}/{sensor}.csv')\n",
        "    # Compute mean value per cycle\n",
        "    data_dict[sensor] = df.mean(axis=1)\n",
        "\n",
        "# Combine into a single DataFrame\n",
        "data = pd.DataFrame(data_dict)\n",
        "profile = pd.read_csv(f'{data_path}/profile.csv')\n",
        "\n",
        "# Merge profile data\n",
        "data = pd.concat([data, profile], axis=1)\n",
        "\n",
        "# Display data shape and check for NaN\n",
        "print(f\"Data shape: {data.shape}\")\n",
        "print(f\"NaN values: {data.isna().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlMwgXD2IwRk"
      },
      "outputs": [],
      "source": [
        "class HydraulicNLPAssistant:\n",
        "    def __init__(self, model, scaler_X, scaler_y):\n",
        "        self.model = model\n",
        "        self.scaler_X = scaler_X\n",
        "        self.scaler_y = scaler_y\n",
        "        self.stop_words = set(stopwords.words('english'))  # Adjust for French if needed\n",
        "        self.intents = {\n",
        "            'predict_se': ['predict', 'forecast', 'efficiency', 'se'],\n",
        "            'optimize_se': ['optimize', 'best', 'settings', 'parameters', 'achieve'],\n",
        "            'general': ['hello', 'help', 'info']\n",
        "        }\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        # Tokenize and clean text\n",
        "        text = text.lower()\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [t for t in tokens if t not in self.stop_words and t.isalnum() or t.isdigit()]\n",
        "        return tokens\n",
        "\n",
        "    def detect_intent(self, tokens):\n",
        "        # Detect intent based on keywords\n",
        "        for token in tokens:\n",
        "            for intent, keywords in self.intents.items():\n",
        "                if token in keywords:\n",
        "                    return intent\n",
        "        return 'general'\n",
        "\n",
        "    def extract_parameters(self, text):\n",
        "        # Extract numerical values (e.g., target SE)\n",
        "        numbers = re.findall(r'[-+]?[0-9]*\\.?[0-9]+', text)\n",
        "        return [float(num) for num in numbers]\n",
        "\n",
        "    def predict_sensor_values(self, target_se):\n",
        "        # Predict sensor values for a target SE\n",
        "        try:\n",
        "            se_scaled = self.scaler_X.transform(np.array([[target_se]]))\n",
        "            sensors_scaled = self.model.predict(se_scaled)\n",
        "            sensors_original = self.scaler_y.inverse_transform(sensors_scaled)\n",
        "            return sensors_original[0]\n",
        "        except Exception as e:\n",
        "            return f\"Error in prediction: {e}\"\n",
        "\n",
        "    def process_message(self, message):\n",
        "        tokens = self.preprocess_text(message)\n",
        "        intent = self.detect_intent(tokens)\n",
        "        params = self.extract_parameters(message)\n",
        "\n",
        "        if intent == 'predict_se':\n",
        "            return {\n",
        "                'type': 'prediction',\n",
        "                'message': 'Prediction of SE is not implemented in this assistant. Please use the Streamlit app for SE predictions.'\n",
        "            }\n",
        "        elif intent == 'optimize_se':\n",
        "            if params:\n",
        "                target_se = params[0]\n",
        "                if 0 <= target_se <= 100:\n",
        "                    sensor_values = self.predict_sensor_values(target_se)\n",
        "                    if isinstance(sensor_values, str):\n",
        "                        return {\n",
        "                            'type': 'error',\n",
        "                            'message': sensor_values\n",
        "                        }\n",
        "                    sensor_dict = {col: round(val, 2) for col, val in zip(['PS1', 'PS2', 'PS3', 'PS5', 'PS6', 'EPS1', 'FS1', 'FS2', 'TS1', 'CE'], sensor_values)}\n",
        "                    return {\n",
        "                        'type': 'optimization',\n",
        "                        'message': f\"To achieve SE of {target_se}%, set the following sensor values:\",\n",
        "                        'sensor_values': sensor_dict\n",
        "                    }\n",
        "                else:\n",
        "                    return {\n",
        "                        'type': 'error',\n",
        "                        'message': 'Target SE must be between 0 and 100.'\n",
        "                    }\n",
        "            else:\n",
        "                return {\n",
        "                    'type': 'error',\n",
        "                    'message': 'Please provide a target SE value (e.g., \"Optimize for SE 95\").'\n",
        "                }\n",
        "        else:\n",
        "            return {\n",
        "                'type': 'general',\n",
        "                'message': 'Hello! I can help predict sensor settings to achieve a target efficiency (SE). Try saying: \"Optimize for SE 95\".'\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmSQFWN0QYlw",
        "outputId": "15826454-46a4-4954-8540-d6f0df367717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Optimize for SE 95\n",
            "Response: {'type': 'optimization', 'message': 'To achieve SE of 95.0%, set the following sensor values:', 'sensor_values': {'PS1': np.float64(95.13), 'PS2': np.float64(60.52), 'PS3': np.float64(-0.67), 'PS5': np.float64(-0.12), 'PS6': np.float64(0.25), 'EPS1': np.float64(572.61), 'FS1': np.float64(7.36), 'FS2': np.float64(3.16), 'TS1': np.float64(245.41), 'CE': np.float64(-299.56)}}\n",
            "\n",
            "Query: Predict efficiency\n",
            "Response: {'type': 'prediction', 'message': 'Prediction of SE is not implemented in this assistant. Please use the Streamlit app for SE predictions.'}\n",
            "\n",
            "Query: Hello, what can you do?\n",
            "Response: {'type': 'general', 'message': 'Hello! I can help predict sensor settings to achieve a target efficiency (SE). Try saying: \"Optimize for SE 95\".'}\n",
            "\n",
            "Query: Achieve SE 110\n",
            "Response: {'type': 'error', 'message': 'Target SE must be between 0 and 100.'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Initialize and test the NLP assistant\n",
        "assistant = HydraulicNLPAssistant(model_inverse_mlp, scaler_X_inverse, scaler_y_inverse)\n",
        "\n",
        "# Test queries\n",
        "test_queries = [\n",
        "    \"Optimize for SE 95\",\n",
        "    \"Predict efficiency\",\n",
        "    \"Hello, what can you do?\",\n",
        "    \"Achieve SE 110\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    response = assistant.process_message(query)\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    print(f\"Response: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py"
      ],
      "metadata": {
        "id": "IZFJUhSciU4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFOsQhRhQpI2",
        "outputId": "05a58db7-35d6-400f-de19-586eb9c3a53f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from joblib import load\n",
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Set page config as the FIRST Streamlit command\n",
        "st.set_page_config(page_title=\"Hydraulic System Assistant\", layout=\"wide\")\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# Custom CSS\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .main-header { font-size: 36px; color: #1f77b4; }\n",
        "    .sidebar .sidebar-content { background-color: #f0f2f6; }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Load models and scalers\n",
        "@st.cache_resource\n",
        "def load_resources():\n",
        "    try:\n",
        "        # LSTM and GRU for SE prediction\n",
        "        model_lstm_path = '/content/drive/MyDrive/Projet_time_series/Models/model_lstm_se.h5'\n",
        "        model_gru_path = '/content/drive/MyDrive/Projet_time_series/Models/model_gru_se.h5'\n",
        "        scaler_X_se_path = '/content/drive/MyDrive/Projet_time_series/Models/scaler_X_se.joblib'\n",
        "        scaler_y_se_path = '/content/drive/MyDrive/Projet_time_series/Models/scaler_y_se.joblib'\n",
        "\n",
        "        # MLP for inverse prediction\n",
        "        model_mlp_path = '/content/drive/MyDrive/Projet_time_series/Models/model_inverse_mlp.joblib'\n",
        "        scaler_X_mlp_path = '/content/drive/MyDrive/Projet_time_series/Models/scaler_X_inverse.joblib'\n",
        "        scaler_y_mlp_path = '/content/drive/MyDrive/Projet_time_series/Models/scaler_y_inverse.joblib'\n",
        "\n",
        "        model_lstm = load_model(model_lstm_path)\n",
        "        model_gru = load_model(model_gru_path)\n",
        "        scaler_X_se = load(scaler_X_se_path)\n",
        "        scaler_y_se = load(scaler_y_se_path)\n",
        "        model_mlp = load(model_mlp_path)\n",
        "        scaler_X_mlp = load(scaler_X_mlp_path)\n",
        "        scaler_y_mlp = load(scaler_y_mlp_path)\n",
        "\n",
        "        return model_lstm, model_gru, scaler_X_se, scaler_y_se, model_mlp, scaler_X_mlp, scaler_y_mlp, None\n",
        "    except Exception as e:\n",
        "        return None, None, None, None, None, None, None, str(e)\n",
        "\n",
        "model_lstm, model_gru, scaler_X_se, scaler_y_se, model_mlp, scaler_X_mlp, scaler_y_mlp, load_error = load_resources()\n",
        "\n",
        "if load_error:\n",
        "    st.error(f\"Error loading resources: {load_error}\")\n",
        "    st.stop()\n",
        "\n",
        "# Load sample data\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    sensors = ['PS1', 'PS2', 'PS3', 'PS5', 'PS6', 'EPS1', 'FS1', 'FS2', 'TS1', 'CE', 'SE']\n",
        "    data_path = '/content/drive/MyDrive/Projet_time_series/Data_csv/'\n",
        "    data_dict = {}\n",
        "    for sensor in sensors:\n",
        "        try:\n",
        "            df = pd.read_csv(f'{data_path}/{sensor}.csv')\n",
        "            data_dict[sensor] = df.mean(axis=1)\n",
        "        except FileNotFoundError:\n",
        "            st.warning(f\"Data file for {sensor} not found. Skipping.\")\n",
        "            data_dict[sensor] = pd.Series(np.nan, index=range(2205))\n",
        "    return pd.DataFrame(data_dict)\n",
        "\n",
        "data = load_data()\n",
        "\n",
        "# Predict SE for all cycles\n",
        "@st.cache_data\n",
        "def predict_se_all_cycles(model, data):\n",
        "    sensor_columns = ['PS1', 'PS2', 'PS3', 'PS5', 'PS6', 'EPS1', 'FS1', 'FS2', 'TS1', 'CE']\n",
        "    X = data[sensor_columns].values\n",
        "    X_scaled = scaler_X_se.transform(X)\n",
        "    X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
        "    se_scaled = model.predict(X_reshaped, verbose=0)\n",
        "    se_original = scaler_y_se.inverse_transform(se_scaled)\n",
        "    return np.clip(se_original.flatten(), 0, 100)\n",
        "\n",
        "se_pred_lstm_all = predict_se_all_cycles(model_lstm, data)\n",
        "se_pred_gru_all = predict_se_all_cycles(model_gru, data)\n",
        "\n",
        "# NLP Assistant Class\n",
        "class HydraulicNLPAssistant:\n",
        "    def __init__(self, model_lstm, model_gru, scaler_X_se, scaler_y_se, model_mlp, scaler_X_mlp, scaler_y_mlp):\n",
        "        self.model_lstm = model_lstm\n",
        "        self.model_gru = model_gru\n",
        "        self.scaler_X_se = scaler_X_se\n",
        "        self.scaler_y_se = scaler_y_se\n",
        "        self.model_mlp = model_mlp\n",
        "        self.scaler_X_mlp = scaler_X_mlp\n",
        "        self.scaler_y_mlp = scaler_y_mlp\n",
        "        self.stop_words = set(stopwords.words('french'))\n",
        "        self.intents = {\n",
        "            'predict_se': ['pr√©dire', 'pr√©voir', 'efficacit√©', 'se'],\n",
        "            'optimize_se': ['optimiser', 'meilleur', 'param√®tres', 'atteindre'],\n",
        "            'general': ['bonjour', 'aide', 'info']\n",
        "        }\n",
        "        self.sensor_columns = ['PS1', 'PS2', 'PS3', 'PS5', 'PS6', 'EPS1', 'FS1', 'FS2', 'TS1', 'CE']\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        text = text.lower()\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [t for t in tokens if t not in self.stop_words and (t.isalnum() or t.isdigit())]\n",
        "        return tokens\n",
        "\n",
        "    def detect_intent(self, tokens):\n",
        "        for token in tokens:\n",
        "            for intent, keywords in self.intents.items():\n",
        "                if token in keywords:\n",
        "                    return intent\n",
        "        return 'general'\n",
        "\n",
        "    def extract_parameters(self, text):\n",
        "        numbers = re.findall(r'[-+]?[0-9]*\\.?[0-9]+', text)\n",
        "        return [float(num) for num in numbers]\n",
        "\n",
        "    def validate_sensors(self, sensor_values):\n",
        "        warnings = []\n",
        "        for col, val in zip(self.sensor_columns, sensor_values):\n",
        "            if col.startswith('PS') and val < 0:\n",
        "                warnings.append(f\"Avertissement: {col} pression ({val:.2f}) est n√©gative.\")\n",
        "            elif col.startswith('TS') and (val < 0 or val > 100):\n",
        "                warnings.append(f\"Avertissement: {col} temp√©rature ({val:.2f}) hors plage 0-100¬∞C.\")\n",
        "            elif col == 'CE' and (val < 0 or val > 100):\n",
        "                warnings.append(f\"Avertissement: {col} efficacit√© ({val:.2f}) hors plage 0-100%.\")\n",
        "        return warnings\n",
        "\n",
        "    def predict_se(self, sensor_values, model):\n",
        "        try:\n",
        "            if len(sensor_values) != len(self.sensor_columns):\n",
        "                return None, [f\"Erreur: {len(sensor_values)} valeurs fournies, {len(self.sensor_columns)} attendues ({', '.join(self.sensor_columns)}).\"]\n",
        "            sensor_df = pd.DataFrame([sensor_values], columns=self.sensor_columns)\n",
        "            sensor_scaled = self.scaler_X_se.transform(sensor_df)\n",
        "            sensor_reshaped = sensor_scaled.reshape((sensor_scaled.shape[0], 1, sensor_scaled.shape[1]))\n",
        "            se_scaled = model.predict(sensor_reshaped, verbose=0)\n",
        "            se_original = self.scaler_y_se.inverse_transform(se_scaled)\n",
        "            se_clipped = np.clip(se_original[0][0], 0, 100)\n",
        "            return se_clipped, []\n",
        "        except Exception as e:\n",
        "            return None, [f\"Erreur de pr√©diction SE: {e}\"]\n",
        "\n",
        "    def predict_sensor_values(self, target_se):\n",
        "        try:\n",
        "            se_scaled = self.scaler_X_mlp.transform(np.array([[target_se]]))\n",
        "            sensors_scaled = self.model_mlp.predict(se_scaled)\n",
        "            sensors_original = self.scaler_y_mlp.inverse_transform(sensors_scaled)\n",
        "            warnings = self.validate_sensors(sensors_original[0])\n",
        "            return sensors_original[0], warnings\n",
        "        except Exception as e:\n",
        "            return np.zeros(len(self.sensor_columns)), [f\"Erreur de pr√©diction inverse: {str(e)}\"]\n",
        "\n",
        "    def process_message(self, message):\n",
        "        tokens = self.preprocess_text(message)\n",
        "        intent = self.detect_intent(tokens)\n",
        "        params = self.extract_parameters(message)\n",
        "\n",
        "        if intent == 'predict_se':\n",
        "            if len(params) == len(self.sensor_columns):\n",
        "                sensor_values = params\n",
        "                se_lstm, warnings_lstm = self.predict_se(sensor_values, self.model_lstm)\n",
        "                se_gru, warnings_gru = self.predict_se(sensor_values, self.model_gru)\n",
        "                if se_lstm is not None and se_gru is not None:\n",
        "                    return {\n",
        "                        'type': 'prediction',\n",
        "                        'message': f\"Efficacit√© syst√®me (SE) pr√©dite:\\n- LSTM: {se_lstm:.2f}%\\n- GRU: {se_gru:.2f}%\",\n",
        "                        'warnings': warnings_lstm + warnings_gru\n",
        "                    }\n",
        "                else:\n",
        "                    return {\n",
        "                        'type': 'error',\n",
        "                        'message': warnings_lstm[0] if warnings_lstm else warnings_gru[0]\n",
        "                    }\n",
        "            else:\n",
        "                return {\n",
        "                    'type': 'error',\n",
        "                    'message': f\"Veuillez fournir {len(self.sensor_columns)} valeurs de capteurs dans l'ordre: {', '.join(self.sensor_columns)}.\"\n",
        "                }\n",
        "        elif intent == 'optimize_se':\n",
        "            if params:\n",
        "                target_se = params[0]\n",
        "                if 0 <= target_se <= 100:\n",
        "                    sensor_values, warnings = self.predict_sensor_values(target_se)\n",
        "                    if sensor_values is not None:\n",
        "                        sensor_dict = {col: round(val, 2) for col, val in zip(self.sensor_columns, sensor_values)}\n",
        "                        return {\n",
        "                            'type': 'optimization',\n",
        "                            'message': f\"Pour atteindre SE de {target_se}%, d√©finissez les valeurs suivantes:\",\n",
        "                            'sensor_values': sensor_dict,\n",
        "                            'warnings': warnings\n",
        "                        }\n",
        "                    else:\n",
        "                        return {\n",
        "                            'type': 'error',\n",
        "                            'message': warnings[0]\n",
        "                        }\n",
        "                else:\n",
        "                    return {\n",
        "                        'type': 'error',\n",
        "                        'message': 'SE cible doit √™tre entre 0 et 100.'\n",
        "                    }\n",
        "            else:\n",
        "                return {\n",
        "                    'type': 'error',\n",
        "                    'message': 'Veuillez fournir une valeur SE cible (ex: \"Optimiser pour SE 95\").'\n",
        "                }\n",
        "        else:\n",
        "            return {\n",
        "                'type': 'general',\n",
        "                'message': 'Bonjour! Je peux optimiser les param√®tres pour une efficacit√© cible (SE) ou pr√©dire SE √† partir des capteurs. Ex: \"Optimiser pour SE 95\" ou \"Pr√©dire SE avec 95.13, 60.52, 0, 0, 0.25, 572.32, 7.34, 3.1, 40, 20\".'\n",
        "            }\n",
        "\n",
        "# Initialize assistant\n",
        "assistant = HydraulicNLPAssistant(model_lstm, model_gru, scaler_X_se, scaler_y_se, model_mlp, scaler_X_mlp, scaler_y_mlp)\n",
        "\n",
        "# Main UI\n",
        "st.markdown('<h1 class=\"main-header\"> Hydraulic System Assistant</h1>', unsafe_allow_html=True)\n",
        "\n",
        "# Sidebar navigation\n",
        "st.sidebar.title(\"Navigation\")\n",
        "page = st.sidebar.selectbox(\"Choisir une page:\", [\"Tableau de Bord\", \"Chatbot\", \"Pr√©diction SE\", \"Pr√©diction Inverse\"])\n",
        "\n",
        "# Dashboard Page\n",
        "if page == \"Tableau de Bord\":\n",
        "    st.header(\" Tableau de Bord\")\n",
        "    st.write(\"Vue d'ensemble de l'efficacit√© (SE) et des donn√©es des capteurs.\")\n",
        "\n",
        "    # Plot SE over cycles (Real vs Predicted LSTM and GRU)\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=data.index, y=data['SE'], mode='lines', name='Efficacit√© R√©elle (SE)'))\n",
        "    fig.add_trace(go.Scatter(x=data.index, y=se_pred_lstm_all, mode='lines', name='Efficacit√© Pr√©dite (LSTM)', line=dict(dash='dash')))\n",
        "    fig.add_trace(go.Scatter(x=data.index, y=se_pred_gru_all, mode='lines', name='Efficacit√© Pr√©dite (GRU)', line=dict(dash='dot')))\n",
        "    fig.update_layout(title='Efficacit√© R√©elle vs Pr√©dite par Cycle', xaxis_title='Cycle', yaxis_title='SE (%)')\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    # Correlation heatmap\n",
        "    st.subheader(\"Corr√©lations des Capteurs\")\n",
        "    corr = data[['SE', 'PS1', 'FS1', 'TS1', 'CE']].corr()\n",
        "    fig = go.Figure(data=go.Heatmap(z=corr.values, x=corr.columns, y=corr.columns, colorscale='Viridis'))\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "# Chatbot Page\n",
        "elif page == \"Chatbot\":\n",
        "    st.header(\"ü§ñ Assistant NLP\")\n",
        "    st.write(\"Interagissez avec l'assistant pour optimiser l'efficacit√© ou pr√©dire SE.\")\n",
        "\n",
        "    user_input = st.text_input(\"Entrez votre message:\", \"\")\n",
        "    if st.button(\"Envoyer\"):\n",
        "        response = assistant.process_message(user_input)\n",
        "        if response['type'] == 'prediction':\n",
        "            st.success(response['message'])\n",
        "            if response.get('warnings'):\n",
        "                st.warning(\"\\n\".join(response['warnings']))\n",
        "        elif response['type'] == 'optimization':\n",
        "            st.success(response['message'])\n",
        "            if response.get('sensor_values'):\n",
        "                st.write(\"Valeurs des capteurs:\", response['sensor_values'])\n",
        "            if response.get('warnings'):\n",
        "                st.warning(\"\\n\".join(response['warnings']))\n",
        "        elif response['type'] == 'error':\n",
        "            st.error(response['message'])\n",
        "        else:\n",
        "            st.info(response['message'])\n",
        "\n",
        "# Prediction SE Page\n",
        "elif page == \"Pr√©diction SE\":\n",
        "    st.header(\" Pr√©diction de l'Efficacit√© Syst√®me (SE)\")\n",
        "    st.write(\"Entrez les valeurs des capteurs pour pr√©dire SE avec LSTM et GRU.\")\n",
        "\n",
        "    sensor_columns = ['PS1', 'PS2', 'PS3', 'PS5', 'PS6', 'EPS1', 'FS1', 'FS2', 'TS1', 'CE']\n",
        "    sensor_values = []\n",
        "    for sensor in sensor_columns:\n",
        "        value = st.number_input(f\"Valeur pour {sensor}\", value=0.0, step=0.1)\n",
        "        sensor_values.append(value)\n",
        "\n",
        "    if st.button(\"Pr√©dire SE\"):\n",
        "        warnings = assistant.validate_sensors(sensor_values)\n",
        "        if warnings:\n",
        "            st.warning(\"\\n\".join(warnings))\n",
        "        if len(sensor_values) == len(sensor_columns):\n",
        "            input_df = pd.DataFrame([sensor_values], columns=sensor_columns)\n",
        "            input_scaled = scaler_X_se.transform(input_df)\n",
        "            input_reshaped = input_scaled.reshape((1, 1, input_scaled.shape[1]))\n",
        "\n",
        "            se_lstm_scaled = model_lstm.predict(input_reshaped, verbose=0)\n",
        "            se_lstm = scaler_y_se.inverse_transform(se_lstm_scaled)[0][0]\n",
        "            se_gru_scaled = model_gru.predict(input_reshaped, verbose=0)\n",
        "            se_gru = scaler_y_se.inverse_transform(se_gru_scaled)[0][0]\n",
        "\n",
        "            st.success(f\"Pr√©diction SE (LSTM): {se_lstm:.2f}%\")\n",
        "            st.success(f\"Pr√©diction SE (GRU): {se_gru:.2f}%\")\n",
        "\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Bar(x=['LSTM', 'GRU'], y=[se_lstm, se_gru], name='Pr√©diction SE'))\n",
        "            fig.update_layout(title='Comparaison des Pr√©dictions SE', yaxis_title='SE (%)', yaxis_range=[0, 100])\n",
        "            st.plotly_chart(fig)\n",
        "        else:\n",
        "            st.error(f\"Veuillez fournir {len(sensor_columns)} valeurs de capteurs.\")\n",
        "\n",
        "# Prediction Inverse Page\n",
        "elif page == \"Pr√©diction Inverse\":\n",
        "    st.header(\"Pr√©diction Inverse (SE vers Capteurs)\")\n",
        "    st.write(\"Entrez une valeur cible pour SE pour pr√©dire les valeurs des capteurs.\")\n",
        "\n",
        "    target_se = st.number_input(\"Cible SE (%)\", min_value=0.0, max_value=100.0, value=50.0)\n",
        "    if st.button(\"Pr√©dire Capteurs\"):\n",
        "        se_scaled = scaler_X_mlp.transform(np.array([[target_se]]))\n",
        "        sensors_scaled = model_mlp.predict(se_scaled)\n",
        "        sensors_original = scaler_y_mlp.inverse_transform(sensors_scaled)[0]\n",
        "        sensor_dict = {col: round(val, 2) for col, val in zip(['PS1', 'PS2', 'PS3', 'PS5', 'PS6', 'EPS1', 'FS1', 'FS2', 'TS1', 'CE'], sensors_original)}\n",
        "\n",
        "        warnings = []\n",
        "        for col, val in sensor_dict.items():\n",
        "            if col.startswith('PS') and val < 0:\n",
        "                warnings.append(f\"Avertissement: {col} pression ({val:.2f}) est n√©gative.\")\n",
        "            elif col.startswith('TS') and (val < 0 or val > 100):\n",
        "                warnings.append(f\"Avertissement: {col} temp√©rature ({val:.2f}) hors plage 0-100¬∞C.\")\n",
        "            elif col == 'CE' and (val < 0 or val > 100):\n",
        "                warnings.append(f\"Avertissement: {col} efficacit√© ({val:.2f}) hors plage 0-100%.\")\n",
        "\n",
        "        st.success(f\"Pr√©diction des valeurs des capteurs pour SE = {target_se}%:\")\n",
        "        st.write(sensor_dict)\n",
        "        if warnings:\n",
        "            st.warning(\"\\n\".join(warnings))\n",
        "\n",
        "# Run the app\n",
        "if __name__ == \"__main__\":\n",
        "    st.sidebar.write(\"Derni√®re mise √† jour: 07:47 PM +01, 08/06/2025\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfSJcxklQuT5",
        "outputId": "ab910921-e0fc-4d43-89ba-e3b4c7aff703"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35.227.50.79\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.227.50.79:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0Kyour url is: https://three-bats-stay.loca.lt\n",
            "2025-06-13 13:39:22.725261: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749821962.757348   34971 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749821962.767468   34971 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-13 13:39:22.798178: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-06-13 13:39:27.540856: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Obtenir l'adresse IP publique\n",
        "!wget -q -O - ipv4.icanhazip.com\n",
        "\n",
        "# D√©marrer l'application Streamlit et exposer avec localtunnel\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}